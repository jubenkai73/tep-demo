name: TEP Machine Learning Pipeline

on:
  push:
    branches: [ main, master, api ]
  pull_request:
    branches: [ main ]

jobs:
  continuous-integration:
    runs-on: ubuntu-latest

    steps:
      # 1. Essential: Download code from the repository
      - name: Checkout Code
        uses: actions/checkout@v4

      # 2. Setup Python environment for unit testing
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # 3. Install core dependencies for local validation
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pandas>=2.3.3 numpy>=1.26.4 scikit-learn joblib psutil

      # 4. Run Unit Tests (Validates data_loader logic and fixes)
      - name: Run Unit Tests
        run: |
          export PYTHONPATH=$PYTHONPATH:$(pwd)
          python -m pytest tests/ -v

      # 5. Setup Docker environment for the pipeline
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # 6. Configure Kaggle Credentials for data ingestion
      - name: Create Kaggle Config
        run: |
          mkdir -p ~/.kaggle
          echo '{"username":"${{ secrets.KAGGLE_USERNAME }}","key":"${{ secrets.KAGGLE_KEY }}"}' > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      # 7. Execute Ingestion & Preprocessing
      - name: Data Ingestion and Preprocessing
        [cite_start]run: docker compose up --build downloader [cite: 1]

      # 8. Train Models (Detector & Diagnostician)
      - name: Model Training
        [cite_start]run: docker compose up --build trainer [cite: 1]

      # 9. Performance Audit
      - name: Run Evaluation
        [cite_start]run: docker compose up --build evaluator [cite: 1]

      # 10. Display metrics in GitHub Logs
      - name: Display Audit Report
        run: |
          if [ -f data/models/audit_report.txt ]; then
            cat data/models/audit_report.txt
          else
            echo "Audit report missing!"
            exit 1
          fi

      # 11. Archive models as artifacts
      - name: Upload Trained Models
        uses: actions/upload-artifact@v4
        with:
          name: tep-models
          path: data/models/
